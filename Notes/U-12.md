**Google Cloud Architecture**

*Loose Coupling with Pub/Sub*

Whenever you want to decouple a publisher, consider Pub/Sub. Here Pub/Sub is used in the microservice architectures, IOT Architectures, Streaming Architectures. Here the architecture goes like you have mobile apps, on-prem services running or IOT services which are running and sending stream to Topic which is further being used with the subscriptions which takes the data to their different destinations like datawarehouse or much more.

*Cloud Dataproc*

Cloud dataproc is a fully managed and highly scalable service for running Apache Spark and Apache Hadoop based workloads. It supports variety of jobs like Spark, PySpark, SparkR, Hive, SparkSQL, Pig, Hadoop. This is mainly used to perform the complex batch processing.

It has multiple cluster modes like Single Node, Standard or Highly Availibility which has 3 masters nodes. It makes use of the virtual machine or regular/preemptible VMs.

Usecase: This is used to move your Hadoop and Spark clusters to the cloud. This lets you perform your machine learning and AI development using the Open Source frameworks.

Alternative to dataproc is BigQuery which can be used to run SQL queries on Petabytes. You can go towards Dataproc if you need more than queries (Example: Complex Batch processing machine learning and AI workloads).

Alternative to dataproc is Dataflow which can be simple pipelines without managing clusters and it is serverless so you do not need to manage the servers by yourself.

*Architecture 1 - Big Data Flow - Batch Ingest*

```
                -->     Cloud Dataproc  --|
                |                         | 
Cloud Storage ---->     Data Prep       ------>   BigQuery
                |                         |
                -->     Cloud Dataflow  --|
```

Here the scenario is something like this you have a lot of data in Cloud Storage and you want to process it till bigquery. Here we will be using ETL also known as Extract, Transform and Load to load the data into Bigquery.

Dataprep which is an another service offering by Google Cloud which is used for intelligent data service for visually exploring, cleaning, and preparing data for analysis, reporting and ML else in simple you can say it is used to clean and prepare the data.

Dataflow can be used to create the data pipelines (and do ETL Transactions), it is recommended if you want to have complex logic in place.

If you have hefty much of data processing work with bigdata workloads you can make use of Dataproc service which makes use of Spark and Hadoop.

As after this once your data is in BigQuery you can make use of the Data Studio which is one of the offering by google cloud which is used to visualize your data in BigQuery. It is mostly used to unlock the power of your data with the interactive dashboards and beautiful reports.

You can also make use of Looker where you can connect your data sources so you can get business intelligence out of it.

*Architecture 2 - Streaming Data*

```
                                          ----->    BigQuery
                                          |
Cloud Pub/Sub   --->    Cloud Dataflow  ---
                                          |
                                          ----->    Cloud BigTable
```

Here you have to handle the streaming data. Here we are having Pub/Sub to receive the messages from the subscriptions on the topic. If you have a bit of more complex data processing you can have the Dataflow in place as it will be able to analyse, aggregate and filter the data.

Now you can load your data into BigQuery or whether in Cloud BigTable.

If you have pre-defined time series analytics, storing the data in Bigtable makes more sense that gives you the ability to perform rapid analysis.

For ad hoc complex analysis, you can go ahead with BigQuery.

*Architecture 3 - IOT*

```
Cloud IOT Core
       |
       |
       V
Cloud Pub/Sub
       |
       |        ----->  Cloud Datastore
       V        |
Cloud Dataflow------->  BigQuery
                |
                ----->  Cloud BigTable
```

IOT Core is a offering of Google cloud intended for IOT based workloads, which is used to manage IOT (Registration, Authenticationb and Authorization operations) for devices. Here it used to Send/Receive messages/Real-time telemetry from/to IOT devices.

As you come to know about the word messages you must have Cloud Pub/Sub in place which is a durable message ingestion service (allows the buffering).

Now you can have Dataflow so you can do the ETL and processing data. Here you can have Cloud Functions as well so they can trigger the alerts

At Last we have data storage and analytics usecase that makes,

the IOT Data available to mobile or webapps you can make use of Datastore or filestore,

if you want to execute the pre-defined time series queries or real time analysis you can make use of Bigtable,

if you want to make more complex or ad hoc analytics/analysis you have BigQuery as your solution.

*Architecture 4 - Data Lakes*

![Architecture 4](https://github.com/cloud-devops-enthusiast/Google-Cloud-Platform_Cloud-Digital-Leader_Certification-Exam-Preparation/blob/cafbcf52ccf296a9a510fcb45bb0ecb72892814b/Images/How-to-build-a-data-lake-on-Google-Cloud-Platform-2.png)

It used for big data solutions that have complex. Here the workloads that can be made by collecting, analyzing, reporting, analytics, machine learning and visualizing huge datasets. Here the usecase is like that it should scale seamlessly and also provide flexibility while saving the costs.

Here comes the solution to all above requirements as *Datalake* which is a single platform with the combination of solutions for data storage, data management and data analytics. Here as per the architecture you can have it for storage which gives you the flexibility for the Storage services where the Cloud Storage comes into the picture which has a Low Cost + Durability + Performance + Flexible Processing.

For the data ingestion usecase you can make the utilization of below services based out of usecase. It is one of main thing from the big data lifecycle.
- Streaming Data: Cloud Pub/Sub + Cloud Dataflow
- Batch: Transfer Service + Transfer Appliance + gsutil

Now here the data is available in the cloud storage, now comes the Data processing in the picture.

For Processing and Analytics usecase:
- You can run the SQL queries using BigQuery or you can use Dataproc which is managed hadoop and spark cluster service. Here you can have the data directly from the cloud storage.
- Data Mining and Exploration: You can clean and transform your raw data with dataprep. You can also have cloud datalab (Which is the data science libraries such as Tensorflow and NumPy) for exploring, more of here you can have you code to do so.

*API Challenges*

In today's world most of the applications are build on REST APIs here you have multiple resources like (/todos,/todos/{id},etc) and can have actions in the same way with the HTTP methods like GET, PUT, POST, DELETE, etc.

Managing REST API is not an easy task as:
- Here you've to take care of the authentication and authorization.
- You've to set the limits (rate limiting, quotas) for your API users.
- You've to be carefull while implementing different versions of your APIs.
- You've to implement monitoring, caching and a lot of other features.

Now we will be looking towards the solutions with the APIs in Google Cloud:
- Apigee API Management: It is a comprehensive API management platform
  - It comes with deployment options across Cloud or on-premise or hybrid environment, so is is more of cross cloud platform.
  - APIGEE is a very complex product as it covers out the entire API life cycle, so you can design, secure, publish, analyze, Monitor and Monitize APIs.
  - It has features that let the developer and partners integrating at the same place.
  - It also supports complex integrations like REST, gRPC, NON-gRPC-REST, integrate with GCP, on-premise or hybrid apps.

Cloud Endpoints these are the basic API for management of Google Cloud Backends. It is little complicated to setup: You need to build a container and deploy to cloud run. This supports REST API and gRPC.

API Gateway, which is newer, simpler API management for Google Cloud Backends about which setup process is simple and supports REST API and gRPC.

*Machine Learning*

Machine learning lets you learn from the examples which are further used to create a model, now this model can be used further to make predictions.

Challengs with machine learning is as with the number of examples needed is more and Availability of skilled personnel is also pretty high. The biggest pain regarding implementing machine learning is MLOps.

*ML in Google Cloud*

Machine learning service in google cloud comes with pre-trained models like,

- Speech-to-text API: This converts speech into text.
- Text-to-Speech API: This lets you convert text to speech.
- Translation API: Translate texts into more than one hundred language.
- Natural Language API: This allows you to derive insights from the unstructured text.
- Cloud Vision API: It is a recommended service for generic usecases like identifying there is a cat in a picture or not or in easy way you can say it helps you to classify images into the predefined categories like classifying images, detecting objects or faces, reading the printed words.

Building Custom models in Google Cloud:

- Auto ML: This is a service that allows you to build custom models with minimum ML expertise and efforts. In this service Auto ML Vision lets you build custom models based on images. For example if you want identify the type of houses this service will help you identify hthem based on the categories like Modern, Retro, Flats, Vilas and so on.