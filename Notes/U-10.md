**DEVOPS in GCP**

*DevOps*

DevOps bridges the gap between the Business, Development and operations team where every team focuses on their individual specified tasks. This whole process is for the sake of making the process of communication (Taking the team at a single platform), in Feedback (Taking regular feedbacks and fixing it in the early stages only) and last is the Automation (Which involves of Automation testing, infrastructure provisioning, deployment and monitoring).

*DevOps- CI, CD*

- Continuous Integration: It takes the control from the code commit step taking it to the next step of having your unit tests as of anything fails it will be easy to fix the things right on the go and packaging the software seamlessly.

- Continuous Deployment: Here you continuous deploy to the test environments.

- Continuous Delivery: This lets you have your newest approved version of the software to be deployed in the production environment.

![CI-CD](https://github.com/cloud-devops-enthusiast/Google-Cloud-Platform_Cloud-Digital-Leader_Certification-Exam-Preparation/blob/db06e0a0b45eefc91166ee8a70a0a2558a7c5b4d/Images/Asset-33-1.jpg)

Things which we can do:

- Static Code Analysis    
  - This process involves the check for the coding standards while being committed into the version control for which we can use the softwares like lint or sonar.
  - You can also have the static security checks which lets you to identify the security issues for which you have softwares like Veracode or static code analyzer.

- Runtime Checks
  - You can detect the flaws in your applications by running the vulnerability scans using the automated tools that can scan the web applications for the security vulnerabilities.

- Tests
  - You can use tools like JUnit, pytest or Jasmine for creating the unit test reports.
  - You can the automation tests and integrate them to create the reports using the tools like Selenium, Robot Framework, Cucumber, etc. These tools can be used for the system tests as well which lets you have check wiuh other applications.
  - You can have sanity tests in place which describes well about the basic functionalities of the running application.
  - You can also plan for the regression which can have multiple number of testcases which can give you more coverage over the whole functionalities.

*Devops CI-CD tools*

- Cloud Source Repositories is a service which can be used to store your code and gives you all features of the fully featured, private git repository.

- Container Registry is a managed service similar to of a docker hub which can be stored to your Docker Images.

- Jenkins is a Continuous Integration tool.
 
- Cloud Build is a managed service that lets you build the deployable artifacts or (jars or docker images) from the source code and configuration.

- Spinnaker is a tool that lets you deploy your code while providing multi cloud support and allows you to do seamless deliveries. Here it supports the deployments to Google Compute Engine, Google Kuberenetes Engine and other cloud platforms. Spinnaker supports blue green deployment, A/B deployment or canary deployment strategies.

You can easily create a DevOps based deployment using cloud run and cloud build using below one steps:

- When the developer commits the code into the cloud source repository, it checkouts the code from the cloud source repository.

- As this checkout step gets over the build is initiated to create a Docker Image

- Now after creating the Docker image you need to store it so here you can make use of the container registry.

- Now you can configure this created docker image to be used on Cloud Run.

*DevOps: Infrastructure as Code*

IaC lets you treat your infrastructure same as how you take the application code, this lets you keep track of the infrastructure you provision with their changes over the period of time so here the version control keeps the logs and everything at a single place.

This also lets you have repeatability or reuse the scripts for creating similar environments.

This whole Infrastructure as Code has two key parts
  
  - Infrastructure Provisioning: Under this you provision compute, database, storage and networking resource using an open source and cloud neutral technology named "Terraform". There are managed services provided by GCP themselves also known as the Google Cloud Deployment Manager where you write your requirement into the template and can use them to provision the resources.

  - Configuration Management is about having all the right check boxes crossed opr having the right softwares installed and tools on the provisioned resources, here you can make use of the tools like Chef, Puppet, Ansible and SaltStack. You can keep this in your list if you have multiple machines in place and want to have all with same stack.

There are different kind of operations with the services intended for DevOps for them:

<table>
<tr>
<th>Operations</th>
<th>GCP Service</th>
</tr>
<tr>
<td>Monitoring: Metrics and Alerts</td>
<td>Cloud Monitoring</td>
</tr>
<tr>
<td>Centralized Logging Solution</td>
<td>Cloud Logging</td>
</tr>
<tr>
<td>Audit Logging</td>
<td>Cloud Audit Logs</td>
</tr>
<tr>
<td>Real-time execution monitoring</td>
<td>Error Reporting</td>
</tr>
<tr>
<td>Live Debugging</td>
<td>Cloud Debugger</td>
</tr>
<tr>
<td>Distributed Tracing</td>
<td>Cloud Trace</td>
</tr>
<tr>
<td>Statistical, Low-Overhead Profiler</td>
<td>Cloud Profiler</td>
</tr>
</table>

*Cloud Operations Scenarios - Microservices*

<table>
<tr>
<th>Scenario</th>
<th>Service</th>
</tr>
<tr>
<td>I want to get metrics related to a specific microservice instance</td>
<td>Cloud Monitoring</td>
</tr>
<tr>
<td>I want to look at the logs for a specific microservice</td>
<td>Cloud Logging</td>
</tr>
<tr>
<td>I want to track exceptions happening in a specific microservice</td>
<td>Error Reporting</td>
</tr>
<tr>
<td>I want to trace request across microservices</td>
<td>Cloud Trace</td>
</tr>
<tr>
<td>I want to solve a performance issue in a specific microservice</td>
<td>Cloud Profiler</td>
</tr>
</table>

*Site Reliability Engineering(SRE)*

SRE teams focuses on every aspect of the application like availability, latency, performance, efficiency, change, management, monitoring, emergency response and capacity planning.

Key principles of SRE:

- Manage by Service Level Objectives (SLOs)

- Minimize Toil

- Move Fast by Reducing Cost of Failure

- Share Ownership with Developers

*SRE Key Metrics*

- Service Level Indicator (SLI): It is a measure the aspect of a service, in other words it is more of the overall metrics of the service. It covers categories like Availability, Throughput, Latency, Throughput, Durability, Correctness(or Error Rate). You can have the SLI's agreegated over 1 minute or so.

- Service Level Objective (SLO): SLI + Target
Here the target is something you want to achieve like Availability, Durability, Uptime, Downtime and so on. Similarly it adds on to 99.99% Availability or 99.999999999% Durability. Here the response time is cut off to 99th percentile- 1 Second. Therefore choosing an appropriate SLO is a complex thing.

- Service Level Agreement (SLA): SLO + Consequences (Contract)
In simple words you and your customer is agreeing on some points and alongside making a wholesome contract as if some things go wrong or elsewise it will be easy to resolve while fighting for the legally or in other words is the consequence of not meeting an SLO which are define in the contract. If you want to ensure your SLAs are properly met you must have Stricter internal SLOs than the external SLAs.

- Error Budgets: (100% - SLO)
It is defined more of by the relibility objectives. This is used to manage the development lifecycle and velocity. It is the depriciated value from the SLOs.

*SRE Best Practices*

- Handelling the excess Loads:
  - Load Shedding: Reduce or set the limit here you reject all the excess requests
    - API Limits
      - You can different SLAs for different customers based on the services and usecases.
    - Streaming Data
      - If you're aggregating time series stream data, in some cases you can drop a part of data or elsewise ignore some percentage of streaming messaged at the peak timing.
  - Reduce the Quality of Service:
    - For instance you have a clothing website dont't send the request and all the traffic to recommendations API, you can send the hardcoded set of products in the time of exceess load.
    - Not everytime this should be done example do not make this with payment gateway
- Avoiding Cascading Failures: Prevent from regular failures
  - Plan to avoid trashing
    - Circuit Breaker: Consider i have two microservices and one of them is overloaded of failure api calls so for some time it will not keep sending the requests and can return the hardcoded responses in place.
  - Reduced Quality Service which is similar to returning the hardcoded response.
- Penetration Testing
  - This is a simulation of the cyber attacks with an objective of finding security vulnerabilities.
  - This kind of testing need to be authorized from the project owners
  - Here you do not need to inform Google
    - Just keep this in mind that you're only testing your projects and are in compliance with the terms of service
  - This testing can either be white box testing (where the hacker is given with all the information about the infrastructure and applications) or black box (here no information is provided to the hacker)
- Load Testing: (JMeter, LoadRunner, Locust, Gatling etc)
  - This testing lets you simulate the real world traffic as closely as possible.
  - Resilience Testing: Resilience is the ability of the system what is used to provide the acceptable behavior even when one or more parts of the system fails or in simple words how the things goes if something turns bad. This is done to check how the application will work under stress.
  - Approaches:
    - Chaos Testing (Simian Army)- This is used to fail one or more layers of the application. This unleashes a wild monkey with a weapon in your data center that lets that monkey do anything like randomly shoot down your instance and break the cables.
    - Add huge amount of stress on one of the layers.
    - One thing to keep included in your testing is your network including VPN, Cloud Interconnect, etc.
      - Check for conditions like if the direct interconnect fails, do we fall back to for VPN
      - Check for what happens when internet is down.
    - Best Practice: DiRT (Discovery Recovery Testiing at Google)
      - This lets you plan and execute the outages for a defined period of time.
      - Scenario: Disconnecting a complete datacenter.

*Some Things to Remember:*

- Container Registry can be used to store your docker images.

- Google Cloud Deployment Manager is a recommended Infrastructure as Code service in google cloud.

- Cloud Monitoring is a service that can be used for monitoring CPU Utilization of your Compute Engine VMs.

- Error Reporting can be used to do real time exception monitoring in Google Cloud.

- If you want to deploy an application using Cloud Run and want to implement CI-CD you can use Cloud Build to run your build.